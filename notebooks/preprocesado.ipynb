{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2qdVVlOGGWNX"
   },
   "source": [
    "# Magic Personality Matcher - Preprocesamiento de datos\n",
    "\n",
    "Para evitar tener que preprocesar los datos cada vez que abrimos el Google Colab vamos a realizar tanto particionado de los datos como su preprocesamiento en este notebook aparte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fase 1 - Cargar el dataset\n",
    "\n",
    "Lo primero es cargar el dataset con Pandas y seleccionar la cantidad de filas que queremos usar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24a2l03s6PVk",
    "outputId": "94476243-85aa-46e5-805a-94eac9fbc952"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "general counts\n",
      "personality\n",
      "7     160219\n",
      "3     134612\n",
      "4     103804\n",
      "8     103124\n",
      "11     95476\n",
      "12     77502\n",
      "15     68449\n",
      "2      46803\n",
      "6      46244\n",
      "5      41960\n",
      "16     37019\n",
      "1      33532\n",
      "10     23052\n",
      "14     13500\n",
      "9      12765\n",
      "13     11361\n",
      "Name: count, dtype: int64\n",
      "used dataset info\n",
      "(1009422, 2)\n",
      "   personality                                               post\n",
      "0            4  @Pericles216 @HierBeforeTheAC @Sachinettiyil T...\n",
      "1            4  @HierBeforeTheAC @Pericles216 @Sachinettiyil A...\n",
      "2            4  @HierBeforeTheAC @Pericles216 @Sachinettiyil Y...\n",
      "3            4  @HierBeforeTheAC @Pericles216 @Sachinettiyil Y...\n",
      "4            4  @HierBeforeTheAC @Pericles216 @Sachinettiyil T...\n",
      "personality\n",
      "7     160219\n",
      "3     134612\n",
      "4     103804\n",
      "8     103124\n",
      "11     95476\n",
      "12     77502\n",
      "15     68449\n",
      "2      46803\n",
      "6      46244\n",
      "5      41960\n",
      "16     37019\n",
      "1      33532\n",
      "10     23052\n",
      "14     13500\n",
      "9      12765\n",
      "13     11361\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "raw_data = pd.read_csv(\"dataset_definitivo.csv\")\n",
    "print(\"general counts\")\n",
    "print(raw_data['personality'].value_counts())\n",
    "training_data = raw_data\n",
    "\n",
    "print(\"used dataset info\")\n",
    "print(training_data.shape)\n",
    "print(training_data.head())\n",
    "print(training_data['personality'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fase 2 - Filtrado de Stopwords, Tokenización y Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpqMuv9eMDco"
   },
   "source": [
    "El preprocesamiento de texto se realiza usando las stopwords y el tokenizer de la librería de lenguaje natural de Python. Primero definimos las stopwords, que serán las de la librería de Python y las personalidades Myers-Briggs para evitar introducir sesgos, como que, si se menciona una personalidad, que esta no se tenga en cuenta para decidir la del autor. Luego se usa el PorterStemmer para obtener la “raíz” de las palabras. Entonces el resultado es una nueva columna que contiene los posts preprocesados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "id": "zpL_KohnCtQd",
    "outputId": "ea21a2ca-0eab-45a5-9841-b94a6db658c5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/mario/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/mario/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa1517b95e6c4209bac7ac450b3d37c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1009422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personality</th>\n",
       "      <th>post</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>@Pericles216 @HierBeforeTheAC @Sachinettiyil T...</td>\n",
       "      <td>pericles216 hierbeforetheac sachinettiyil pope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>@HierBeforeTheAC @Pericles216 @Sachinettiyil A...</td>\n",
       "      <td>hierbeforetheac pericles216 sachinettiyil perp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>@HierBeforeTheAC @Pericles216 @Sachinettiyil Y...</td>\n",
       "      <td>hierbeforetheac pericles216 sachinettiyil open...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>@HierBeforeTheAC @Pericles216 @Sachinettiyil Y...</td>\n",
       "      <td>hierbeforetheac pericles216 sachinettiyil know...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@HierBeforeTheAC @Pericles216 @Sachinettiyil T...</td>\n",
       "      <td>hierbeforetheac pericles216 sachinettiyil like...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009417</th>\n",
       "      <td>5</td>\n",
       "      <td>i loved the whole mcyt/geoguesser fandom colli...</td>\n",
       "      <td>love whole mcyt geoguess fandom collis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009418</th>\n",
       "      <td>5</td>\n",
       "      <td>@paytonstyleslol ILL BE THINKING REAL HARD</td>\n",
       "      <td>paytonstyleslol ill think real hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009419</th>\n",
       "      <td>5</td>\n",
       "      <td>i am at olive garden and my sister ordered the...</td>\n",
       "      <td>oliv garden sister order 5 chees someth withou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009420</th>\n",
       "      <td>5</td>\n",
       "      <td>@paytonstyleslol you’re so right</td>\n",
       "      <td>paytonstyleslol right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009421</th>\n",
       "      <td>5</td>\n",
       "      <td>@paytonstyleslol THIS IS VERY TRUE I THINK</td>\n",
       "      <td>paytonstyleslol true think</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1009422 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         personality                                               post  \\\n",
       "0                  4  @Pericles216 @HierBeforeTheAC @Sachinettiyil T...   \n",
       "1                  4  @HierBeforeTheAC @Pericles216 @Sachinettiyil A...   \n",
       "2                  4  @HierBeforeTheAC @Pericles216 @Sachinettiyil Y...   \n",
       "3                  4  @HierBeforeTheAC @Pericles216 @Sachinettiyil Y...   \n",
       "4                  4  @HierBeforeTheAC @Pericles216 @Sachinettiyil T...   \n",
       "...              ...                                                ...   \n",
       "1009417            5  i loved the whole mcyt/geoguesser fandom colli...   \n",
       "1009418            5         @paytonstyleslol ILL BE THINKING REAL HARD   \n",
       "1009419            5  i am at olive garden and my sister ordered the...   \n",
       "1009420            5                   @paytonstyleslol you’re so right   \n",
       "1009421            5         @paytonstyleslol THIS IS VERY TRUE I THINK   \n",
       "\n",
       "                                            processed_text  \n",
       "0        pericles216 hierbeforetheac sachinettiyil pope...  \n",
       "1        hierbeforetheac pericles216 sachinettiyil perp...  \n",
       "2        hierbeforetheac pericles216 sachinettiyil open...  \n",
       "3        hierbeforetheac pericles216 sachinettiyil know...  \n",
       "4        hierbeforetheac pericles216 sachinettiyil like...  \n",
       "...                                                    ...  \n",
       "1009417             love whole mcyt geoguess fandom collis  \n",
       "1009418                paytonstyleslol ill think real hard  \n",
       "1009419  oliv garden sister order 5 chees someth withou...  \n",
       "1009420                              paytonstyleslol right  \n",
       "1009421                         paytonstyleslol true think  \n",
       "\n",
       "[1009422 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "from multiprocessing import cpu_count\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "\n",
    "STOPS = set(stopwords.words(\"english\"))\n",
    "CUSTOM_STOPS=set(['istj', 'isfj', 'infj', 'intj', 'istp', 'isfp', 'infp', 'intp', 'estp', 'esfp', 'enfp', 'entp', 'estj', 'esfj', 'enfj', 'entj'])\n",
    "\n",
    "def process_text(post):\n",
    "    try:\n",
    "        post = post.lower()\n",
    "        post = re.sub('https?://[^\\s<>\"]+|www\\.[^\\s<>\"]+',' ',post)\n",
    "        post = re.sub('[^0-9a-z]',' ',post)\n",
    "        return \" \".join([ps.stem(w) for w in word_tokenize(post) if not w in STOPS and w not in CUSTOM_STOPS])\n",
    "    except:\n",
    "        print(\"problem with: \", post)\n",
    "\n",
    "preprocessedData = training_data.loc[:]\n",
    "\n",
    "num_processes = cpu_count()\n",
    "\n",
    "preprocessedData['processed_text'] = process_map(process_text, training_data['post'], max_workers=num_processes, chunksize=10)\n",
    "\n",
    "preprocessedData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fase 3 - Particionar el dataset para entrenamiento y validación\n",
    "Se divide el dataset en 2 para tener 80% datos de entrenamiento y 20% de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = preprocessedData['processed_text']\n",
    "Y = preprocessedData['personality']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGpqAmK4MHJl"
   },
   "source": [
    "## Fase 4 - Bolsa de palabras\n",
    "\n",
    "Se crea una bolsa de palabras utilizando TfidVectorizer, que se basa en la frecuencia de las palabras para determinar su importancia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ZdzH4i6TEL2",
    "outputId": "d1d9174f-80a1-40f8-e12e-d5364b3eaba6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train bag of words:\n",
      "(807537, 334414)\n",
      "X_test bag of words:\n",
      "(201885, 334414)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Datos de entrenamiento\n",
    "bagOfWordsModel = TfidfVectorizer()\n",
    "train_textsBoW = bagOfWordsModel.fit_transform(X_train)\n",
    "print(\"X_train bag of words:\")\n",
    "print(train_textsBoW.shape)\n",
    "\n",
    "# Datos pruebas\n",
    "test_textsBoW = bagOfWordsModel.transform(X_test)\n",
    "print(\"X_test bag of words:\")\n",
    "print(test_textsBoW.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VOyc2LmHMZ5p"
   },
   "source": [
    "## Fase 5 - Guardar el resultado\n",
    "\n",
    "Utilizamos joblib para guardar estas bolsas de palabras para poder usarlas para entrenamiento sin tener que repetir el proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k4j6m5N1E1Cs",
    "outputId": "bac883e4-66d3-49c1-b0ac-925a587c80e3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51f9a3cd51d24c3fa81af6c8944e0530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.contrib.concurrent import process_map,thread_map\n",
    "from joblib import dump\n",
    "\n",
    "def multiargs_dump(args_tuple):\n",
    "    dump(args_tuple[0], args_tuple[1])\n",
    "\n",
    "\n",
    "thread_map(multiargs_dump,\n",
    "    (\n",
    "        (train_textsBoW, \"X_train.lzma\"),\n",
    "        (test_textsBoW, \"X_test.lzma\"),\n",
    "        (y_train, \"y_train.lzma\"),\n",
    "        (y_test, \"y_test.lzma\"),\n",
    "        (bagOfWordsModel, \"bag_of_words.lzma\")\n",
    "    ))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
