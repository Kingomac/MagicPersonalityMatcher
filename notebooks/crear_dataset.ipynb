{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78302de6-83f3-4ff0-b4b4-5d35eebc26ee",
   "metadata": {},
   "source": [
    "# Magic Personality Matcher - Creación de dataset\n",
    "\n",
    "Para usar como fuente encontramos varios datasets que podríamos usar y decidimos juntarlos todos para tener más datos, por si queremos ampliarla cantidad de datos usada para entrenamiento fácilmente.\n",
    "\n",
    "Los datasets usados son los siguientes:\n",
    "- [Twitter MBTI](https://www.kaggle.com/datasets/mazlumi/mbti-personality-type-twitter-dataset)\n",
    "- [MBTI 1](https://www.kaggle.com/datasets/datasnaek/mbti-type)\n",
    "- [MBTI 500](https://www.kaggle.com/datasets/zeyadkhalid/mbti-personality-types-500-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "324ec49a-db6e-4b02-90f4-2f129eafdb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "personality_num = {\n",
    "    'ISTJ': 1,\n",
    "    'ISFJ': 2,\n",
    "    'INFJ': 3,\n",
    "    'INTJ': 4,\n",
    "    'ISTP': 5,\n",
    "    'ISFP': 6,\n",
    "    'INFP': 7,\n",
    "    'INTP': 8,\n",
    "    'ESTP': 9,\n",
    "    'ESFP': 10,\n",
    "    'ENFP': 11,\n",
    "    'ENTP': 12,\n",
    "    'ESTJ': 13,\n",
    "    'ESFJ': 14,\n",
    "    'ENFJ': 15,\n",
    "    'ENTJ': 16\n",
    "}\n",
    "\n",
    "num_personality = {\n",
    "    1: 'ISTJ',\n",
    "    2: 'ISFJ',\n",
    "    3: 'INFJ',\n",
    "    4: 'INTJ',\n",
    "    5: 'ISTP',\n",
    "    6: 'ISFP',\n",
    "    7: 'INFP',\n",
    "    8: 'INTP',\n",
    "    9: 'ESTP',\n",
    "    10: 'ESFP',\n",
    "    11: 'ENFP',\n",
    "    12: 'ENTP',\n",
    "    13: 'ESTJ',\n",
    "    14: 'ESFJ',\n",
    "    15: 'ENFJ',\n",
    "    16: 'ENTJ'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63b9b26-7401-4a6f-9552-fa5143c39f42",
   "metadata": {},
   "source": [
    "Primero cargamos los datasets con Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee132e91-0833-4625-9533-aa6c86462806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Twitter MBTI\n",
      "   Unnamed: 0                                               text label\n",
      "0           0  @Pericles216 @HierBeforeTheAC @Sachinettiyil T...  intj\n",
      "1           1  @Hispanthicckk Being you makes you look cute||...  intj\n",
      "2           2  @Alshymi Les balles sont réelles et sont tirée...  intj\n",
      "3           3  I'm like entp but idiotic|||Hey boy, do you wa...  intj\n",
      "4           4  @kaeshurr1 Give it to @ZargarShanif ... He has...  intj\n",
      "(7811, 3)\n",
      "Dataset MBTI 1\n",
      "   type                                              posts\n",
      "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
      "1  ENTP  'I'm finding the lack of me in these posts ver...\n",
      "2  INTP  'Good one  _____   https://www.youtube.com/wat...\n",
      "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
      "4  ENTJ  'You're fired.|||That's another silly misconce...\n",
      "(8675, 2)\n",
      "Dataset MBTI 500\n",
      "                                               posts  type\n",
      "0  know intj tool use interaction people excuse a...  INTJ\n",
      "1  rap music ehh opp yeah know valid well know fa...  INTJ\n",
      "2  preferably p hd low except wew lad video p min...  INTJ\n",
      "3  drink like wish could drink red wine give head...  INTJ\n",
      "4  space program ah bad deal meing freelance max ...  INTJ\n",
      "(106067, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the csv file in\n",
    "dataset_twittermbti = pd.read_csv('twitter_MBTI.csv')\n",
    "dataset_mbti1 = pd.read_csv('mbti_1.csv')\n",
    "dataset_mbti500 = pd.read_csv('mbti_500.csv')\n",
    "\n",
    "# Print info\n",
    "print(\"Dataset Twitter MBTI\")\n",
    "print(dataset_twittermbti.head())\n",
    "print(dataset_twittermbti.shape)\n",
    "\n",
    "print(\"Dataset MBTI 1\")\n",
    "print(dataset_mbti1.head())\n",
    "print(dataset_mbti1.shape)\n",
    "\n",
    "print(\"Dataset MBTI 500\")\n",
    "print(dataset_mbti500.head())\n",
    "print(dataset_mbti500.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c617795-076e-4394-9f38-b2808688d98d",
   "metadata": {},
   "source": [
    "Renombramos las columnas para que coincidan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb0fe464-0c8a-4244-a8aa-560d19f0c051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "dataset_twittermbti.rename(\n",
    "    columns={'label': 'personality', 'text': 'post'}, inplace=True)\n",
    "\n",
    "dataset_mbti1.rename(\n",
    "    columns={'type': 'personality', 'posts': 'post'}, inplace=True)\n",
    "\n",
    "dataset_mbti500.rename(\n",
    "    columns={'type': 'personality', 'posts': 'post'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40045f12-0442-417a-9f89-8054a45d05fc",
   "metadata": {},
   "source": [
    "Concatenamos los 3 datasets y transformamos todas las personalidades a mayúsculas y seleccionamos solo las columnas que nos interesan de personalidad y post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7859725-1c01-4206-aa9e-f166cd484c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(\n",
    "    [dataset_twittermbti, dataset_mbti500, dataset_mbti1])\n",
    "df = df[['personality', 'post']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f9db64-d13d-41d5-9a16-eb2335d34b39",
   "metadata": {},
   "source": [
    "Como los datasets tienen varios posts por entrada hay que dividirlos para que tengan su entrada propia en el entrenamiento. Además, se descartan los posts con menos de 20 caracteres por ser irrelevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9363968d-2edc-4d6f-9452-76cd25d054da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['post'] = df['post'].str.split(\"\\|\\|\\|\")\n",
    "df = df.explode('post').reset_index(drop=True)\n",
    "df = df[df['post'].str.len() >= 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795c7aac-6bf6-4cd9-9dc2-80ca0979ee8f",
   "metadata": {},
   "source": [
    "Se sustituyen las personalidades por números para que el dataset use menos memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a2ce1f-f366-497d-b178-fc696094a0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['personality'] = df['personality'].apply(\n",
    "    lambda x: personality_num[x.upper()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3fe025-06d0-4ebf-ace3-cb1d2c1c6fec",
   "metadata": {},
   "source": [
    "Por último guardamos el resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1fc21f2-6c7f-4b46-b80b-289596812404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Definitivo\n",
      "(1519248, 2)\n",
      "Head\n",
      "   personality                                               post\n",
      "0            4  @Pericles216 @HierBeforeTheAC @Sachinettiyil T...\n",
      "1            4  @HierBeforeTheAC @Pericles216 @Sachinettiyil A...\n",
      "2            4  @HierBeforeTheAC @Pericles216 @Sachinettiyil Y...\n",
      "3            4  @HierBeforeTheAC @Pericles216 @Sachinettiyil Y...\n",
      "4            4  @HierBeforeTheAC @Pericles216 @Sachinettiyil T...\n",
      "Tail\n",
      "         personality                                               post\n",
      "1622106            7  I was going to close my facebook a few months ...\n",
      "1622107            7  30 Seconds to Mars - All of my collections. It...\n",
      "1622108            7  I have seen it, and i agree. I did actually th...\n",
      "1622109            7  Ok so i have just watched Underworld 4 (Awaken...\n",
      "1622110            7  I would never want to turn off my emotions. so...\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(\n",
    "    \"dataset_definitivo.csv\", index=False)\n",
    "\n",
    "print(\"Dataset Definitivo\")\n",
    "print(df.shape)\n",
    "print(\"Head\")\n",
    "print(df.head())\n",
    "print(\"Tail\")\n",
    "print(df.tail())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
